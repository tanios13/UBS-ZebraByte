{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/skylab_instagram_datathon_dataset.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "df[\"period_end_date\"] = pd.to_datetime(df['period_end_date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Sort DataFrame by 'date' column in ascending order\n",
    "df = df.sort_values(by='period_end_date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed = df.rename(columns={\"business_entity_doing_business_as_name\": \"brand\", \"legal_entity_name\": \"company\", \"ultimate_parent_legal_entity_name\": \"parent_company\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676558"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_brands = df_renamed[df_renamed[\"brand\"] == \"All Brands\"]\n",
    "brands = df_renamed[df_renamed[\"brand\"] != \"All Brands\"]\n",
    "len(brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630721"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop data with na for the last 6 years\n",
    "year_lag = 4\n",
    "na_brands = ['Simmons', 'LP Building Products', 'East Bay', 'Bottega Veneta',\n",
    "       \"Carter's\", 'Sperry', 'Serta', 'Nature Valley', 'Nautica',\n",
    "       'Bobbi Brown', 'Anta', \"OshKosh B'gosh\", 'Kanebo',\n",
    "       'Michelob Ultra', 'Skip Hop', 'Runnerspoint', 'Fashion Nova',\n",
    "       'Modelo', 'Yoplait', 'Invisalign', 'CertainTeed', 'CCC Shoes',\n",
    "       'John Frieda', 'Whiskas', 'Vegetarian Butcher', 'Tempur',\n",
    "       'Breville', 'Schweppes', 'Becca', 'Sizeer', 'iRobot',\n",
    "       'Ninja Kitchen', 'About You', 'Sensai', 'Izod', 'Restylane',\n",
    "       'Ecovacs', \"Beck's\", 'Shark Home', 'Garden Gourmet', 'Revanesse',\n",
    "       'Sol', 'Elemis', 'Hoegaarden', 'Bulgari Beauty', 'Carla Amorim',\n",
    "       'Royal Building Products', 'The Meatless Farm', 'Tineco',\n",
    "       'Roborock', 'Superdown', 'ORCA', 'Burberry Beauty',\n",
    "       'Pure Farmland', 'Spaten', 'Dysport', 'Sculptra', 'Temu',\n",
    "       'Finding Unicorn', 'Pop Mart', 'Rolife', 'Wahoo Fitness',\n",
    "       'Belotero', 'My Shoes', 'Tonica Antarctica', 'Value Village',\n",
    "       'Pacifico', 'ShopGoodwill']\n",
    "# Filter the DataFrame\n",
    "brands = brands[~brands[\"brand\"].isin(na_brands)]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "len(brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused years\n",
    "max_date = brands[\"period_end_date\"].max()\n",
    "brands = brands[brands[\"period_end_date\"] > max_date - pd.DateOffset(years=year_lag)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "\n",
    "    data = data[[ \"followers\", \"likes\",  \"videos\", \"pictures\", \"comments\", \"period_end_date\", \"brand\"]].copy()\n",
    "    data['content'] = data['videos'] + data['pictures']\n",
    "    data['engagement'] = data['likes'] + data['comments']\n",
    "    data['value'] = data['engagement'] / data['content']\n",
    "    data = data.drop([\"pictures\", \"followers\", \"content\", \"engagement\", \"videos\", \"likes\", \"comments\"], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "brands = preprocess_data(brands)\n",
    "#all_brands = preprocess_data(all_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_end_date</th>\n",
       "      <th>brand</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400848</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Build A Bear</td>\n",
       "      <td>4882.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276585</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Alexandre Birman</td>\n",
       "      <td>1734.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569777</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>4016.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331996</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Gap</td>\n",
       "      <td>408.079727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Tim Horton's</td>\n",
       "      <td>4942.420000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       period_end_date             brand        value\n",
       "400848      2019-09-21      Build A Bear  4882.647059\n",
       "276585      2019-09-21  Alexandre Birman  1734.718750\n",
       "569777      2019-09-21      Under Armour  4016.847682\n",
       "331996      2019-09-21               Gap   408.079727\n",
       "2298        2019-09-21      Tim Horton's  4942.420000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the data and the regression line\n",
    "plt.hist(brands[\"value\"].values, bins=50, color='skyblue', edgecolor='black')  # Adjust bins for desired granularity\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Data')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "limit = brands['period_end_date'].max() - pd.DateOffset(months=3)\n",
    "train_data = brands[brands['period_end_date'] < limit]\n",
    "test_data = brands[brands['period_end_date'] >= limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_end_date</th>\n",
       "      <th>brand</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400848</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Build A Bear</td>\n",
       "      <td>4882.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276585</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Alexandre Birman</td>\n",
       "      <td>1734.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569777</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>4016.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331996</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Gap</td>\n",
       "      <td>408.079727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Tim Horton's</td>\n",
       "      <td>4942.420000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       period_end_date             brand        value\n",
       "400848      2019-09-21      Build A Bear  4882.647059\n",
       "276585      2019-09-21  Alexandre Birman  1734.718750\n",
       "569777      2019-09-21      Under Armour  4016.847682\n",
       "331996      2019-09-21               Gap   408.079727\n",
       "2298        2019-09-21      Tim Horton's  4942.420000"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelers = []\n",
    "to_label = [\"brand\"]\n",
    "\n",
    "for l in to_label:\n",
    "    labeler = LabelEncoder()\n",
    "    train_data.loc[:, l] = labeler.fit_transform(train_data[l])\n",
    "    labelers.append(labeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"previous_value\"] = train_data[\"value\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_end_date</th>\n",
       "      <th>brand</th>\n",
       "      <th>value</th>\n",
       "      <th>previous_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400848</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>50</td>\n",
       "      <td>4882.647059</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276585</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>10</td>\n",
       "      <td>1734.718750</td>\n",
       "      <td>4882.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569777</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>385</td>\n",
       "      <td>4016.847682</td>\n",
       "      <td>1734.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331996</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>140</td>\n",
       "      <td>408.079727</td>\n",
       "      <td>4016.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>371</td>\n",
       "      <td>4942.420000</td>\n",
       "      <td>408.079727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255793</th>\n",
       "      <td>2023-06-10</td>\n",
       "      <td>325</td>\n",
       "      <td>57.571429</td>\n",
       "      <td>3353.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520782</th>\n",
       "      <td>2023-06-10</td>\n",
       "      <td>200</td>\n",
       "      <td>920.333333</td>\n",
       "      <td>57.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697110</th>\n",
       "      <td>2023-06-10</td>\n",
       "      <td>356</td>\n",
       "      <td>38.811321</td>\n",
       "      <td>920.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459619</th>\n",
       "      <td>2023-06-10</td>\n",
       "      <td>189</td>\n",
       "      <td>862.400000</td>\n",
       "      <td>38.811321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99078</th>\n",
       "      <td>2023-06-10</td>\n",
       "      <td>253</td>\n",
       "      <td>288.613678</td>\n",
       "      <td>862.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81900 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       period_end_date  brand        value  previous_value\n",
       "400848      2019-09-21     50  4882.647059        0.000000\n",
       "276585      2019-09-21     10  1734.718750     4882.647059\n",
       "569777      2019-09-21    385  4016.847682     1734.718750\n",
       "331996      2019-09-21    140   408.079727     4016.847682\n",
       "2298        2019-09-21    371  4942.420000      408.079727\n",
       "...                ...    ...          ...             ...\n",
       "255793      2023-06-10    325    57.571429     3353.240000\n",
       "520782      2023-06-10    200   920.333333       57.571429\n",
       "697110      2023-06-10    356    38.811321      920.333333\n",
       "459619      2023-06-10    189   862.400000       38.811321\n",
       "99078       2023-06-10    253   288.613678      862.400000\n",
       "\n",
       "[81900 rows x 4 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "# Preprocess the data\n",
    "# Assuming 'period_end_date' is not needed for modeling\n",
    "features = ['brand', 'previous_value']\n",
    "target = 'value'\n",
    "\n",
    "# Group the data by (brand, compset, compset_group)\n",
    "grouped_data = train_data.groupby('brand')\n",
    "\n",
    "# Initialize lists to store sequences and targets\n",
    "sequences = []\n",
    "targets = []\n",
    "seq_length = len(train_data[\"period_end_date\"].unique())\n",
    "\n",
    "# Iterate over each group\n",
    "for group, group_df in grouped_data:\n",
    "    # Sort by period_end_date if needed\n",
    "    group_df = group_df.sort_values(by='period_end_date')\n",
    "    \n",
    "    # Extract features and target\n",
    "    X_group = group_df[features]  # Exclude the 'value' column\n",
    "    y_group = group_df[target]\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X_group = X_group.values\n",
    "    y_group = y_group.values\n",
    "    \n",
    "    sequences.append(X_group)\n",
    "    targets.append(y_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "sequences = np.array(sequences, dtype=np.float32)\n",
    "targets = np.array(targets, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((420, 195), (420, 195, 2))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape, sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 462.36365,  479.7143 ,  479.05   , ...,  354.32144,  383.5    ,\n",
       "         358.14285],\n",
       "       [4292.614  , 4223.397  , 4606.901  , ...,  632.36664,  710.1739 ,\n",
       "         647.3182 ],\n",
       "       [1550.7885 , 1207.415  , 1118.7222 , ...,        nan,        nan,\n",
       "               nan],\n",
       "       ...,\n",
       "       [1516.6154 , 1509.0834 , 1538.8462 , ...,  728.6667 ,  682.     ,\n",
       "         606.05884],\n",
       "       [7637.2026 , 8447.85   , 8823.1    , ..., 5961.5513 , 6855.893  ,\n",
       "        7673.4263 ],\n",
       "       [3027.452  , 3662.126  , 4058.4653 , ..., 1226.7546 , 1218.5175 ,\n",
       "        1137.303  ]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: nan\n",
      "Epoch 2/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: nan\n",
      "Epoch 3/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19a8380ec40>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(seq_length, len(features))),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "# Train model\n",
    "model.fit(sequences, targets, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Generate predictions and update input sequence with predicted values\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seq_length):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Predict next value\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m:\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Update output sequence with predicted value\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     output_sequence[:, j:j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m prediction\n",
      "File \u001b[1;32mc:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:442\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m, x, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    440\u001b[0m ):\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;66;03m# Create an iterator that yields batches of input data.\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     epoch_iterator \u001b[38;5;241m=\u001b[39m \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;66;03m# Container that configures and calls callbacks.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:625\u001b[0m, in \u001b[0;36mTFEpochIterator.__init__\u001b[1;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy \u001b[38;5;241m=\u001b[39m distribute_strategy\n\u001b[1;32m--> 625\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedDataset):\n\u001b[0;32m    627\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy\u001b[38;5;241m.\u001b[39mexperimental_distribute_dataset(\n\u001b[0;32m    628\u001b[0m         dataset\n\u001b[0;32m    629\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:634\u001b[0m, in \u001b[0;36mTFEpochIterator._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_iterator\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:236\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    234\u001b[0m     indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mmap(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle)\n\u001b[1;32m--> 236\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n\u001b[0;32m    239\u001b[0m options\u001b[38;5;241m.\u001b[39mexperimental_distribute\u001b[38;5;241m.\u001b[39mauto_shard_policy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    240\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAutoShardPolicy\u001b[38;5;241m.\u001b[39mDATA\n\u001b[0;32m    241\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:215\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset.<locals>.slice_inputs\u001b[1;34m(indices_dataset, inputs)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mtraverse(grab_one, data)\n\u001b[1;32m--> 215\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrab_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Default optimizations are disabled to avoid the overhead of\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# (unnecessary) input pipeline graph serialization & deserialization\u001b[39;00m\n\u001b[0;32m    221\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n",
      "File \u001b[1;32mc:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2299\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2296\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2297\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2298\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2300\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m     37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MapDataset(\n\u001b[0;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:163\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_parallel_calls \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[0;32m    161\u001b[0m     num_parallel_calls, dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint64, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_parallel_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m--> 163\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mparallel_map_dataset_v2(\n\u001b[0;32m    164\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m    166\u001b[0m     f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[0;32m    167\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_parallel_calls,\n\u001b[0;32m    168\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic,\n\u001b[0;32m    169\u001b[0m     use_inter_op_parallelism\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism,\n\u001b[0;32m    170\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[1;32mc:\\Users\\ronan\\miniconda3\\envs\\pai-demos\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:5854\u001b[0m, in \u001b[0;36mparallel_map_dataset_v2\u001b[1;34m(input_dataset, other_arguments, num_parallel_calls, f, output_types, output_shapes, use_inter_op_parallelism, deterministic, preserve_cardinality, metadata, name)\u001b[0m\n\u001b[0;32m   5852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   5853\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 5854\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5855\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mParallelMapDatasetV2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5856\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5857\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_inter_op_parallelism\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5858\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_inter_op_parallelism\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeterministic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5859\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpreserve_cardinality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   5861\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "sequences = np.array(sequences, dtype=np.float32)\n",
    "targets = np.array(targets, dtype=np.float32)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(seq_length, len(features))),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model with autoregression\n",
    "for epoch in range(10):\n",
    "    for i in range(len(sequences)):\n",
    "        # Select a single sequence from the training data\n",
    "        X_train = sequences[i:i+1]\n",
    "        y_train = targets[i:i+1]\n",
    "        \n",
    "        # Initialize output sequence with random values\n",
    "        output_sequence = np.random.rand(*y_train.shape)\n",
    "        \n",
    "        # Generate predictions and update input sequence with predicted values\n",
    "        for j in range(seq_length):\n",
    "            # Predict next value\n",
    "            prediction = model.predict(X_train[:, j:j+1, :], verbose=0)\n",
    "            \n",
    "            # Update output sequence with predicted value\n",
    "            output_sequence[:, j:j+1] = prediction\n",
    "            \n",
    "            # Update input sequence with predicted value\n",
    "            X_train[:, j+1:j+2, :] = prediction\n",
    "        \n",
    "        # Compute loss and perform a single step of gradient descent\n",
    "        loss = model.train_on_batch(sequences[i:i+1], output_sequence)\n",
    "    \n",
    "    # Print loss at the end of each epoch\n",
    "    print(\"Epoch:\", epoch+1, \"Loss:\", loss)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(sequences)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(targets, predictions)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 5.0000000e+00],\n",
       "        [-1.1862062e-02],\n",
       "        [ 6.4800197e-04],\n",
       "        [ 4.6201190e-04],\n",
       "        [ 4.6499050e-04],\n",
       "        [ 4.6494277e-04],\n",
       "        [ 4.6494356e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [ 4.6494353e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04],\n",
       "        [-2.7531324e-04]]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>brand</th>\n",
       "      <th>24S</th>\n",
       "      <th>3CE</th>\n",
       "      <th>A. Lange &amp; Soehne</th>\n",
       "      <th>ANIMALE</th>\n",
       "      <th>Abercrombie &amp; Fitch</th>\n",
       "      <th>Absolut</th>\n",
       "      <th>Academy Sports + Outdoors</th>\n",
       "      <th>Adidas</th>\n",
       "      <th>Aerie</th>\n",
       "      <th>Alexander McQueen</th>\n",
       "      <th>...</th>\n",
       "      <th>YesStyle</th>\n",
       "      <th>Yves Veggie Cuisine</th>\n",
       "      <th>Zalando</th>\n",
       "      <th>Zales</th>\n",
       "      <th>Zara</th>\n",
       "      <th>Zenith</th>\n",
       "      <th>bareMinerals</th>\n",
       "      <th>dd's Discounts</th>\n",
       "      <th>e.l.f.</th>\n",
       "      <th>shopDisney</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period_end_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-21</th>\n",
       "      <td>462.363636</td>\n",
       "      <td>4292.613636</td>\n",
       "      <td>1550.788462</td>\n",
       "      <td>2799.000000</td>\n",
       "      <td>11720.156250</td>\n",
       "      <td>573.181818</td>\n",
       "      <td>375.200000</td>\n",
       "      <td>10325.734884</td>\n",
       "      <td>10498.500000</td>\n",
       "      <td>35858.490909</td>\n",
       "      <td>...</td>\n",
       "      <td>8310.130435</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>718.244444</td>\n",
       "      <td>616.434783</td>\n",
       "      <td>55300.152941</td>\n",
       "      <td>2635.814815</td>\n",
       "      <td>946.110429</td>\n",
       "      <td>1516.615385</td>\n",
       "      <td>7637.202479</td>\n",
       "      <td>3027.451852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-28</th>\n",
       "      <td>479.714286</td>\n",
       "      <td>4223.396947</td>\n",
       "      <td>1207.415094</td>\n",
       "      <td>2305.700000</td>\n",
       "      <td>12177.130435</td>\n",
       "      <td>492.968354</td>\n",
       "      <td>419.071429</td>\n",
       "      <td>11906.115727</td>\n",
       "      <td>9783.582090</td>\n",
       "      <td>35241.844828</td>\n",
       "      <td>...</td>\n",
       "      <td>8241.692857</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>785.987261</td>\n",
       "      <td>738.111111</td>\n",
       "      <td>55192.780488</td>\n",
       "      <td>3140.851852</td>\n",
       "      <td>899.148810</td>\n",
       "      <td>1509.083333</td>\n",
       "      <td>8447.849138</td>\n",
       "      <td>3662.125926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-05</th>\n",
       "      <td>479.050000</td>\n",
       "      <td>4606.900826</td>\n",
       "      <td>1118.722222</td>\n",
       "      <td>1733.142857</td>\n",
       "      <td>13202.235955</td>\n",
       "      <td>475.291139</td>\n",
       "      <td>423.666667</td>\n",
       "      <td>11074.409692</td>\n",
       "      <td>10534.956522</td>\n",
       "      <td>36088.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>8904.857143</td>\n",
       "      <td>136.142857</td>\n",
       "      <td>833.308176</td>\n",
       "      <td>835.473684</td>\n",
       "      <td>62137.209877</td>\n",
       "      <td>3068.785714</td>\n",
       "      <td>866.957576</td>\n",
       "      <td>1538.846154</td>\n",
       "      <td>8823.099138</td>\n",
       "      <td>4058.465409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-12</th>\n",
       "      <td>403.428571</td>\n",
       "      <td>5352.573770</td>\n",
       "      <td>1284.055556</td>\n",
       "      <td>1700.225806</td>\n",
       "      <td>13893.151163</td>\n",
       "      <td>445.824242</td>\n",
       "      <td>416.823529</td>\n",
       "      <td>14781.395161</td>\n",
       "      <td>11213.753623</td>\n",
       "      <td>33689.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>10383.899281</td>\n",
       "      <td>142.555556</td>\n",
       "      <td>827.506173</td>\n",
       "      <td>781.952381</td>\n",
       "      <td>64677.743590</td>\n",
       "      <td>3094.730769</td>\n",
       "      <td>799.922619</td>\n",
       "      <td>1657.625000</td>\n",
       "      <td>9609.865801</td>\n",
       "      <td>4904.058201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-19</th>\n",
       "      <td>406.238095</td>\n",
       "      <td>5150.443548</td>\n",
       "      <td>1261.173077</td>\n",
       "      <td>1688.906250</td>\n",
       "      <td>14522.988372</td>\n",
       "      <td>435.793103</td>\n",
       "      <td>418.823529</td>\n",
       "      <td>16912.980983</td>\n",
       "      <td>12722.492958</td>\n",
       "      <td>33530.147541</td>\n",
       "      <td>...</td>\n",
       "      <td>11506.657143</td>\n",
       "      <td>162.333333</td>\n",
       "      <td>898.223642</td>\n",
       "      <td>850.320000</td>\n",
       "      <td>73407.280000</td>\n",
       "      <td>3457.115385</td>\n",
       "      <td>784.431818</td>\n",
       "      <td>1552.461538</td>\n",
       "      <td>10517.783784</td>\n",
       "      <td>5224.676329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 419 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "brand                   24S          3CE  A. Lange & Soehne      ANIMALE  \\\n",
       "period_end_date                                                            \n",
       "2019-09-21       462.363636  4292.613636        1550.788462  2799.000000   \n",
       "2019-09-28       479.714286  4223.396947        1207.415094  2305.700000   \n",
       "2019-10-05       479.050000  4606.900826        1118.722222  1733.142857   \n",
       "2019-10-12       403.428571  5352.573770        1284.055556  1700.225806   \n",
       "2019-10-19       406.238095  5150.443548        1261.173077  1688.906250   \n",
       "\n",
       "brand            Abercrombie & Fitch     Absolut  Academy Sports + Outdoors  \\\n",
       "period_end_date                                                               \n",
       "2019-09-21              11720.156250  573.181818                 375.200000   \n",
       "2019-09-28              12177.130435  492.968354                 419.071429   \n",
       "2019-10-05              13202.235955  475.291139                 423.666667   \n",
       "2019-10-12              13893.151163  445.824242                 416.823529   \n",
       "2019-10-19              14522.988372  435.793103                 418.823529   \n",
       "\n",
       "brand                  Adidas         Aerie  Alexander McQueen  ...  \\\n",
       "period_end_date                                                 ...   \n",
       "2019-09-21       10325.734884  10498.500000       35858.490909  ...   \n",
       "2019-09-28       11906.115727   9783.582090       35241.844828  ...   \n",
       "2019-10-05       11074.409692  10534.956522       36088.500000  ...   \n",
       "2019-10-12       14781.395161  11213.753623       33689.857143  ...   \n",
       "2019-10-19       16912.980983  12722.492958       33530.147541  ...   \n",
       "\n",
       "brand                YesStyle  Yves Veggie Cuisine     Zalando       Zales  \\\n",
       "period_end_date                                                              \n",
       "2019-09-21        8310.130435           135.000000  718.244444  616.434783   \n",
       "2019-09-28        8241.692857           140.500000  785.987261  738.111111   \n",
       "2019-10-05        8904.857143           136.142857  833.308176  835.473684   \n",
       "2019-10-12       10383.899281           142.555556  827.506173  781.952381   \n",
       "2019-10-19       11506.657143           162.333333  898.223642  850.320000   \n",
       "\n",
       "brand                    Zara       Zenith  bareMinerals  dd's Discounts  \\\n",
       "period_end_date                                                            \n",
       "2019-09-21       55300.152941  2635.814815    946.110429     1516.615385   \n",
       "2019-09-28       55192.780488  3140.851852    899.148810     1509.083333   \n",
       "2019-10-05       62137.209877  3068.785714    866.957576     1538.846154   \n",
       "2019-10-12       64677.743590  3094.730769    799.922619     1657.625000   \n",
       "2019-10-19       73407.280000  3457.115385    784.431818     1552.461538   \n",
       "\n",
       "brand                  e.l.f.   shopDisney  \n",
       "period_end_date                             \n",
       "2019-09-21        7637.202479  3027.451852  \n",
       "2019-09-28        8447.849138  3662.125926  \n",
       "2019-10-05        8823.099138  4058.465409  \n",
       "2019-10-12        9609.865801  4904.058201  \n",
       "2019-10-19       10517.783784  5224.676329  \n",
       "\n",
       "[5 rows x 419 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to pivot table to reshape data into sequences\n",
    "pivot_df = brands.pivot_table(index='period_end_date', columns='brand', values='value', fill_value=0)\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "data = pivot_df.values\n",
    "\n",
    "# Prepare input sequences and corresponding targets\n",
    "X = []\n",
    "y = []\n",
    "seq_length = len(train_data[\"period_end_date\"].unique())\n",
    "\n",
    "for i in range():\n",
    "    X.append(data[i:i+past_years*12])\n",
    "    y.append(data[i+past_years*12:i+past_years*12+future_months])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(X.shape[1], X.shape[2])),\n",
    "    Dense(future_months)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pai-demos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
